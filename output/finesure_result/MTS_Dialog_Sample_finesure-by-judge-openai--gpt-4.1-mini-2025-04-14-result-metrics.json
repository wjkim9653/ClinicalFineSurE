{"factuality_eval_result": {"bAcc": 0.9782608695652174, "pearson_corr": [0.8256410464864421, 5.5181844518654815e-11], "spearman_corr": [0.8537180079663209, 2.5431893267655057e-12], "rank_corr": [0.8164965809277261, 0.1835034190722738]}, "completeness_eval_result": {"pearson_corr": [0.9030193754074447, 1.6125179214001455e-15], "spearman_corr": [0.9126124240874977, 2.427772597794736e-16], "rank_corr": [1.0, 0.0]}, "conciseness_eval_result": {"pearson_corr": [0.5644978808945209, 0.00014813231152329212], "spearman_corr": [0.855762506671301, 1.9831820658224925e-12], "rank_corr": [0.2721655269759087, 0.7278344730240913]}}
